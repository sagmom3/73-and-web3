From computers to Web 2.0

Computer technology came to the point that businesses could communicate together via a network. Networking progressed, making it possible to communicate far away.  In 1970, Arpanet created a network between Stanford and UCLA, which they tried but subsequently crashed on the first attempt. They also built a network between Harvard, MIT, and BBN, the creator of the interface processor used with the network. With the popularity using  eBooks, and messages and emails sent across the pond, 
there was talk about creating an inter-internet. Then there were modems developed and MSG was  created,  Internet with Spam, Bulletin Board System, TCP/IP protocol, and  Domain Naming System (DNS) were all added to the Internet and were important pieces to use the Web as well.

We should point out to everyone that we have an Internet, and then we have the Web, and they are not the same thing. The Internet consists of the actual wires and how they connect to one another to communicate. Early on, this was mostly in the commercial community through the 1980s. Then, driven by the Internet's use, the Web was introduced in the early 90s to the public. The Web is a document and application platform. It consisted of web pages, web apps, and the web browser.   

1989 brought the World Wide Web, a global hypertext system. In 1990, the first commercial dial-up provider, The World, came online, and in that same year Arpanet ceased operating.    A  standard was set, code, HTML, HTTP and URL were developed for WWW t and the first web page was seen in 1991.    Interestingly the WWW was referred to as W3.   1996 saw the Web become commercialized leading to the dotcom collapse four years later, causing huge losses to investors.  

The term "web 1.0" describes a period from 1991 until the early 2000s and was primarily made of read-only content. For those of us living then it was exciting. It was a significant expense to acquire a computer, and it was a job to get familiar with how to use one.   In some circles, the computer was referred to as a glorified typewriter.   

In 2004, was the birth of Web 2.0 which had  websites and apps that are highly interactive, user-driven, and generally connect apps to back-end systems through an API. Web 2.0 is, therefore, described as a read-write web. Web 2.0 allowed better apps to be built on smaller computers and helped move users away from desktops and into mobile units.


Introducing Web3


So what is Web3?  This question has a number of different answers depending where you look.   It is a new version of the current  Web.  It has been referred to as the decentralized Web as opposed to the centralized patterns that emerged in Web 2.0 and before.

I found in my reading a few years ago, this definition to read as follows:

Web 3 is defined as the high-quality content and services produced by gifted individuals and web2 technology as an enabling platform. It is the third generation of websites for internet services.   

While the definition  evolved, the core vision remain the same. In simple terms, Web 3 is a platform containing the decentralized Web,a blockchain systems, and linked data.  Over the last 5 years there has been steady support by people people with a vision that includes: 
      trustless infrastructure, verifiability,
      decentralization, 
     secure communication 
     secure storage,
      secure money, 
      contracts,
     read and write privacy,
    ownership of data 
   dependable, trustless, and robust infrastructure. 

Now we need a way to work on it. At first, and not all that long ago, it was conceptualized how and what to build on Web3. In earlier writings, some building was starting but was using Web 2.0 but that changed with the development of  IPFS.  

And what is IPFS, you say?

IPFS stands for the InterPlanetary File System. It's a peer-to-peer protocol and a network that enables applications and services to use the Internet.  

Note: a peer is a computer system which, for many of us, means just our computer or an app. Peer-to-peer will mean one computer talking to another computer.   

Note: a protocol is essentially a set of rules to follow when one or more computers (or apps) are communicating.  .
 
Because  this network would be a peer-to-peer,  that would make the Web faster, safer, and more open.   Because of content addressing, IPFS  manages the content and facilitates storing as well as tracking a version over time. 

We need to step aside for just a moment to explain. Using the present Internet, you find an item, app, or web page by typing its address in the browser the URL, which then uses a DNS to help ask for the location address that corresponds with that URL via an IP. In short, this just means your browser goes through a series of requests to find a specific server with the content you requested. Your request is then sent to the web server, which then sends the HTML via the HTTP Channel. Finally, your web browser receives the result, closes a connection to the webserver, and lets your browser screen show you what you got.   

Now, when you use the IPFS, you can still type your request in the browser, but instead of finding a server that holds the content, your browser can ask anyone on the network for your content. If found, it is sent back to you.  

We have mentioned that an item is found because of its content and not its location. 
You make a request for content by using a hash, or unique fingerprint, of the file. All files found on IPFS are assigned a hash when they enter the system. A hash identifies the file and doesn't change. IF someone does make changes to an item, the hash also changes, which identifies it as a changed item; thus, when you receive an item response, you can verify that what you asked for is indeed what you receive.       

No other item will ever have the same hash. It is that easy. And it is that quick. It's also secure with no central server required to make any changes to your request, and one of the significant advantages is that it is verifiable since you have the hash that is one of a kind.

IPFS is a distributed system for storing and accessing files, websites, applications, and data. It is for Web3 what HTML is for Web 2.0. Since the information you get from IPFS is content-addressed (again, hash-based and verifiable) and not location addressed, the information can come from any peer/computer and doesn't have to use a server. If that sounds simple, it is. Keep in mind that it took a lot of work from a lot of dedicated people to create this system that works in this fashion in the decentralized Web.   

Now we have a platform, IPFS, where we can now add apps to use Web3. But the developers need a little help to do that. There are companies building tools that help make it faster and easier to build these apps. In developing IPFS, all the apps have to be structured to follow the protocols of IPFS. So tools have been built that can be carried on-board, so to speak, and allow them to do their job well. For the in-depth developer, the libp2p is a modular system of protocols, specifications, and libraries that enable the development of peer-to-peer network applications. Because the definition of peer-to-peer networking is quite broad, Many different kinds of systems have been built that all fall under the umbrella of "peer-to-peer." Suffice to say these elements added to the IPFS, make it possible for everything to talk to each other and work smoothly when processing. This now made it possible to bring in more developers to add their app creations into being on the IPFS. The problem areas addressed in libp2p are the transport of the data, identity using public-key cryptography for peer identity, security, peer routing, peer id, content discovery, and messaging PubSub, which is a way for messaging peers.   





One company that makes it easier for developers is one that I am familiar with called Textile. They build a suite of tools to help developers create custom, decentralized, and resilient applications on IPFS. Their mission is to help applications give their users greater access and control to the data that they create. The tools built by Textile allow developers to create quickly and test their creations to find if they work and change directions quickly if they don't. It is also easy to use the collection of tools built by Textile since they work together seamlessly. It is the perfect way to encourage new developers to try their ideas with positive support.  


 





 

From computers to Web 2.0

Computer technology came to the point that businesses could communicate together via a network. Networking progressed, making it possible to communicate far away.  In 1970, Arpanet created a network between Stanford and UCLA, which they tried but subsequently crashed on the first attempt. They also built a network between Harvard, MIT, and BBN, the creator of the interface processor used with the network. With the popularity using  eBooks, and messages and emails sent across the pond, 
there was talk about creating an inter-internet. Then there were modems developed and MSG was  created,  Internet with Spam, Bulletin Board System, TCP/IP protocol, and  Domain Naming System (DNS) were all added to the Internet and were important pieces to use the Web as well.

We should point out to everyone that we have an Internet, and then we have the Web, and they are not the same thing. The Internet consists of the actual wires and how they connect to one another to communicate. Early on, this was mostly in the commercial community through the 1980s. Then, driven by the Internet's use, the Web was introduced in the early 90s to the public. The Web is a document and application platform. It consisted of web pages, web apps, and the web browser.   

1989 brought the World Wide Web, a global hypertext system. In 1990, the first commercial dial-up provider, The World, came online, and in that same year Arpanet ceased operating.    A  standard was set, code, HTML, HTTP and URL were developed for WWW t and the first web page was seen in 1991.    Interestingly the WWW was referred to as W3.   1996 saw the Web become commercialized leading to the dotcom collapse four years later, causing huge losses to investors.  

The term "web 1.0" describes a period from 1991 until the early 2000s and was primarily made of read-only content. For those of us living then it was exciting. It was a significant expense to acquire a computer, and it was a job to get familiar with how to use one.   In some circles, the computer was referred to as a glorified typewriter.   

In 2004, was the birth of Web 2.0 which had  websites and apps that are highly interactive, user-driven, and generally connect apps to back-end systems through an API. Web 2.0 is, therefore, described as a read-write web. Web 2.0 allowed better apps to be built on smaller computers and helped move users away from desktops and into mobile units.


Introducing Web3


So what is Web3?  This question has a number of different answers depending where you look.   It is a new version of the current  Web.  It has been referred to as the decentralized Web as opposed to the centralized patterns that emerged in Web 2.0 and before.

I found in my reading a few years ago, this definition to read as follows:

Web 3 is defined as the high-quality content and services produced by gifted individuals and web2 technology as an enabling platform. It is the third generation of websites for internet services.   

While the definition  evolved, the core vision remain the same. In simple terms, Web 3 is a platform containing the decentralized Web,a blockchain systems, and linked data.  Over the last 5 years there has been steady support by people people with a vision that includes: 
      trustless infrastructure, verifiability,
      decentralization, 
     secure communication 
     secure storage,
      secure money, 
      contracts,
     read and write privacy,
    ownership of data 
   dependable, trustless, and robust infrastructure. 

Now we need a way to work on it. At first, and not all that long ago, it was conceptualized how and what to build on Web3. In earlier writings, some building was starting but was using Web 2.0 but that changed with the development of  IPFS.  

And what is IPFS, you say?

IPFS stands for the InterPlanetary File System. It's a peer-to-peer protocol and a network that enables applications and services to use the Internet.  

Note: a peer is a computer system which, for many of us, means just our computer or an app. Peer-to-peer will mean one computer talking to another computer.   

Note: a protocol is essentially a set of rules to follow when one or more computers (or apps) are communicating.  .
 
Because  this network would be a peer-to-peer,  that would make the Web faster, safer, and more open.   Because of content addressing, IPFS  manages the content and facilitates storing as well as tracking a version over time. 

We need to step aside for just a moment to explain. Using the present Internet, you find an item, app, or web page by typing its address in the browser the URL, which then uses a DNS to help ask for the location address that corresponds with that URL via an IP. In short, this just means your browser goes through a series of requests to find a specific server with the content you requested. Your request is then sent to the web server, which then sends the HTML via the HTTP Channel. Finally, your web browser receives the result, closes a connection to the webserver, and lets your browser screen show you what you got.   

Now, when you use the IPFS, you can still type your request in the browser, but instead of finding a server that holds the content, your browser can ask anyone on the network for your content. If found, it is sent back to you.  

We have mentioned that an item is found because of its content and not its location. 
You make a request for content by using a hash, or unique fingerprint, of the file. All files found on IPFS are assigned a hash when they enter the system. A hash identifies the file and doesn't change. IF someone does make changes to an item, the hash also changes, which identifies it as a changed item; thus, when you receive an item response, you can verify that what you asked for is indeed what you receive.       

No other item will ever have the same hash. It is that easy. And it is that quick. It's also secure with no central server required to make any changes to your request, and one of the significant advantages is that it is verifiable since you have the hash that is one of a kind.

IPFS is a distributed system for storing and accessing files, websites, applications, and data. It is for Web3 what HTML is for Web 2.0. Since the information you get from IPFS is content-addressed (again, hash-based and verifiable) and not location addressed, the information can come from any peer/computer and doesn't have to use a server. If that sounds simple, it is. Keep in mind that it took a lot of work from a lot of dedicated people to create this system that works in this fashion in the decentralized Web.   

Now we have a platform, IPFS, where we can now add apps to use Web3. But the developers need a little help to do that. There are companies building tools that help make it faster and easier to build these apps. In developing IPFS, all the apps have to be structured to follow the protocols of IPFS. So tools have been built that can be carried on-board, so to speak, and allow them to do their job well. For the in-depth developer, the libp2p is a modular system of protocols, specifications, and libraries that enable the development of peer-to-peer network applications. Because the definition of peer-to-peer networking is quite broad, Many different kinds of systems have been built that all fall under the umbrella of "peer-to-peer." Suffice to say these elements added to the IPFS, make it possible for everything to talk to each other and work smoothly when processing. This now made it possible to bring in more developers to add their app creations into being on the IPFS. The problem areas addressed in libp2p are the transport of the data, identity using public-key cryptography for peer identity, security, peer routing, peer id, content discovery, and messaging PubSub, which is a way for messaging peers.   





One company that makes it easier for developers is one that I am familiar with called Textile. They build a suite of tools to help developers create custom, decentralized, and resilient applications on IPFS. Their mission is to help applications give their users greater access and control to the data that they create. The tools built by Textile allow developers to create quickly and test their creations to find if they work and change directions quickly if they don't. It is also easy to use the collection of tools built by Textile since they work together seamlessly. It is the perfect way to encourage new developers to try their ideas with positive support.  


 





 

From computers to Web 2.0

Computer technology came to the point that businesses could communicate together via a network. Networking progressed, making it possible to communicate far away.  In 1970, Arpanet created a network between Stanford and UCLA, which they tried but subsequently crashed on the first attempt. They also built a network between Harvard, MIT, and BBN, the creator of the interface processor used with the network. With the popularity using  eBooks, and messages and emails sent across the pond, 
there was talk about creating an inter-internet. Then there were modems developed and MSG was  created,  Internet with Spam, Bulletin Board System, TCP/IP protocol, and  Domain Naming System (DNS) were all added to the Internet and were important pieces to use the Web as well.

We should point out to everyone that we have an Internet, and then we have the Web, and they are not the same thing. The Internet consists of the actual wires and how they connect to one another to communicate. Early on, this was mostly in the commercial community through the 1980s. Then, driven by the Internet's use, the Web was introduced in the early 90s to the public. The Web is a document and application platform. It consisted of web pages, web apps, and the web browser.   

1989 brought the World Wide Web, a global hypertext system. In 1990, the first commercial dial-up provider, The World, came online, and in that same year Arpanet ceased operating.    A  standard was set, code, HTML, HTTP and URL were developed for WWW t and the first web page was seen in 1991.    Interestingly the WWW was referred to as W3.   1996 saw the Web become commercialized leading to the dotcom collapse four years later, causing huge losses to investors.  

The term "web 1.0" describes a period from 1991 until the early 2000s and was primarily made of read-only content. For those of us living then it was exciting. It was a significant expense to acquire a computer, and it was a job to get familiar with how to use one.   In some circles, the computer was referred to as a glorified typewriter.   

In 2004, was the birth of Web 2.0 which had  websites and apps that are highly interactive, user-driven, and generally connect apps to back-end systems through an API. Web 2.0 is, therefore, described as a read-write web. Web 2.0 allowed better apps to be built on smaller computers and helped move users away from desktops and into mobile units.


Introducing Web3


So what is Web3?  This question has a number of different answers depending where you look.   It is a new version of the current  Web.  It has been referred to as the decentralized Web as opposed to the centralized patterns that emerged in Web 2.0 and before.

I found in my reading a few years ago, this definition to read as follows:

Web 3 is defined as the high-quality content and services produced by gifted individuals and web2 technology as an enabling platform. It is the third generation of websites for internet services.   

While the definition  evolved, the core vision remain the same. In simple terms, Web 3 is a platform containing the decentralized Web,a blockchain systems, and linked data.  Over the last 5 years there has been steady support by people people with a vision that includes: 
      trustless infrastructure, verifiability,
      decentralization, 
     secure communication 
     secure storage,
      secure money, 
      contracts,
     read and write privacy,
    ownership of data 
   dependable, trustless, and robust infrastructure. 

Now we need a way to work on it. At first, and not all that long ago, it was conceptualized how and what to build on Web3. In earlier writings, some building was starting but was using Web 2.0 but that changed with the development of  IPFS.  

And what is IPFS, you say?

IPFS stands for the InterPlanetary File System. It's a peer-to-peer protocol and a network that enables applications and services to use the Internet.  

Note: a peer is a computer system which, for many of us, means just our computer or an app. Peer-to-peer will mean one computer talking to another computer.   

Note: a protocol is essentially a set of rules to follow when one or more computers (or apps) are communicating.  .
 
Because  this network would be a peer-to-peer,  that would make the Web faster, safer, and more open.   Because of content addressing, IPFS  manages the content and facilitates storing as well as tracking a version over time. 

We need to step aside for just a moment to explain. Using the present Internet, you find an item, app, or web page by typing its address in the browser the URL, which then uses a DNS to help ask for the location address that corresponds with that URL via an IP. In short, this just means your browser goes through a series of requests to find a specific server with the content you requested. Your request is then sent to the web server, which then sends the HTML via the HTTP Channel. Finally, your web browser receives the result, closes a connection to the webserver, and lets your browser screen show you what you got.   

Now, when you use the IPFS, you can still type your request in the browser, but instead of finding a server that holds the content, your browser can ask anyone on the network for your content. If found, it is sent back to you.  

We have mentioned that an item is found because of its content and not its location. 
You make a request for content by using a hash, or unique fingerprint, of the file. All files found on IPFS are assigned a hash when they enter the system. A hash identifies the file and doesn't change. IF someone does make changes to an item, the hash also changes, which identifies it as a changed item; thus, when you receive an item response, you can verify that what you asked for is indeed what you receive.       

No other item will ever have the same hash. It is that easy. And it is that quick. It's also secure with no central server required to make any changes to your request, and one of the significant advantages is that it is verifiable since you have the hash that is one of a kind.

IPFS is a distributed system for storing and accessing files, websites, applications, and data. It is for Web3 what HTML is for Web 2.0. Since the information you get from IPFS is content-addressed (again, hash-based and verifiable) and not location addressed, the information can come from any peer/computer and doesn't have to use a server. If that sounds simple, it is. Keep in mind that it took a lot of work from a lot of dedicated people to create this system that works in this fashion in the decentralized Web.   

Now we have a platform, IPFS, where we can now add apps to use Web3. But the developers need a little help to do that. There are companies building tools that help make it faster and easier to build these apps. In developing IPFS, all the apps have to be structured to follow the protocols of IPFS. So tools have been built that can be carried on-board, so to speak, and allow them to do their job well. For the in-depth developer, the libp2p is a modular system of protocols, specifications, and libraries that enable the development of peer-to-peer network applications. Because the definition of peer-to-peer networking is quite broad, Many different kinds of systems have been built that all fall under the umbrella of "peer-to-peer." Suffice to say these elements added to the IPFS, make it possible for everything to talk to each other and work smoothly when processing. This now made it possible to bring in more developers to add their app creations into being on the IPFS. The problem areas addressed in libp2p are the transport of the data, identity using public-key cryptography for peer identity, security, peer routing, peer id, content discovery, and messaging PubSub, which is a way for messaging peers.   





One company that makes it easier for developers is one that I am familiar with called Textile. They build a suite of tools to help developers create custom, decentralized, and resilient applications on IPFS. Their mission is to help applications give their users greater access and control to the data that they create. The tools built by Textile allow developers to create quickly and test their creations to find if they work and change directions quickly if they don't. It is also easy to use the collection of tools built by Textile since they work together seamlessly. It is the perfect way to encourage new developers to try their ideas with positive support.  


 





 

